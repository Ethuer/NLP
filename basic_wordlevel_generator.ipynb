{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense ,Dropout,LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "badlist = pd.read_csv('data/badlist', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# add spaces to special characters\n",
    "unspaced = r'[\\[\\]\\(\\)\\.\\,\\/\\?\\-\\!\\\"\\;|:]'\n",
    "spaced =  ' \\g<0> '\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    \"\"\"\n",
    "    remove stray characters\n",
    "    \"\"\"\n",
    "    for badchar in badlist:\n",
    "        if badchar in line:\n",
    "            line = re.sub(badchar,'',line)\n",
    "        line = re.sub(unspaced, spaced, line)\n",
    "        line = re.sub('  ',' ',line)\n",
    "        line = re.sub('”','',line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw text files and clean the lines\n",
    "\n",
    "START_STRING = 'BEGIN EPISODE'\n",
    "\n",
    "all_episodes_by_sentence = []\n",
    "\n",
    "for element in os.listdir('house/'):\n",
    "    if 'clean' in element:\n",
    "        with open('house/'+element) as in_raw:\n",
    "            # start token\n",
    "            all_episodes_by_sentence.append(START_STRING)\n",
    "            for (i, line) in enumerate(in_raw):\n",
    "                all_episodes_by_sentence.append(clean_line(line) )\n",
    "        \n",
    "            # end token\n",
    "            all_episodes_by_sentence.append('END EPISODE\\n\\n')\n",
    "            all_episodes_by_sentence.append('------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return sentence.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine text to create a single string for sliceshifting\n",
    "word_dict = {}\n",
    "text = []\n",
    "for sent in all_episodes_by_sentence:\n",
    "    for word in tokenize(sent):\n",
    "        if not word in word_dict:\n",
    "            word_dict[word] = 0\n",
    "        word_dict[word] +=1\n",
    "        text.append(word)\n",
    "#text = [tokenize(sent) for sent in all_episodes_by_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quant = pd.DataFrame.from_dict(word_dict, orient='index').sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29102, 1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_quant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7202, 1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 7202 words occur more than 5 times\n",
    "data_quant.loc[data_quant[0] > 6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_vocabulary = data_quant.loc[data_quant[0] > 7].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preformat to test if this is enough\n",
    "word_dict = {}\n",
    "text = []\n",
    "for sent in all_episodes_by_sentence:\n",
    "    for word in tokenize(sent):\n",
    "        if word in allowed_vocabulary:\n",
    "            if not word in word_dict:\n",
    "                word_dict[word] = 0\n",
    "            word_dict[word] +=1\n",
    "            text.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'begin episode  [ open on a house’s face . his eyes are closed . the picture is not quite in color , but it’s'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text still readable ?\n",
    "' '.join(text[0:25] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7202 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(allowed_vocabulary)\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2word = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 671, 2204,    0, ..., 2162, 2205,   23])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int = np.array([word2idx[c] for c in text])\n",
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 20\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 671, 2204,    0, ..., 2162, 2205,   23])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sequences from character dataset\n",
    "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_shift_input(segment):\n",
    "    \"\"\"\n",
    "    Creates the teaching data by shifting the training data on off to create labeled data\n",
    "    \"\"\"\n",
    "    input_segment = segment[:-1]\n",
    "    target_segment = segment[1:]\n",
    "    return input_segment, target_segment\n",
    "\n",
    "dataset = sequences.map(split_shift_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((20,), (20,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset as prebatched\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "# Length of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# embedding dimension\n",
    "embedding_dim = 300\n",
    "\n",
    "# RNN units\n",
    "rnn_units = 250\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((35, 20), (35, 20)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    i = Input(shape=(None,), batch_size=batch_size )\n",
    "    x = Embedding(vocab_size, embedding_dim)(i)\n",
    "    x = LSTM(rnn_units, \n",
    "             return_sequences=True,\n",
    "             stateful=True,\n",
    "             recurrent_initializer='glorot_uniform')(x)\n",
    "   # x = Dense(vocab_size)(x)\n",
    "    x = Dense(vocab_size)(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f22c45f2d30>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(35, None)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (35, None, 300)           2160600   \n",
      "_________________________________________________________________\n",
      "unified_lstm_14 (UnifiedLSTM (35, None, 250)           551000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (35, None, 7202)          1807702   \n",
      "=================================================================\n",
      "Total params: 4,519,302\n",
      "Trainable params: 4,519,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    \"\"\"\n",
    "    Define loss function \n",
    "    \"\"\"\n",
    "    return sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss =loss)# loss='sparse_categorical_crossentropy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "today = date.today()\n",
    "\n",
    "checkpoint_dir = './word_training_checkpoints_{today}'.format(today=today)\n",
    "\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "# define callbacks\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2137/2137 [==============================] - 18s 8ms/step - loss: 4.6295\n",
      "Epoch 2/12\n",
      "2137/2137 [==============================] - 17s 8ms/step - loss: 4.0789\n",
      "Epoch 3/12\n",
      "2137/2137 [==============================] - 17s 8ms/step - loss: 3.9181\n",
      "Epoch 4/12\n",
      "2137/2137 [==============================] - 17s 8ms/step - loss: 3.8133\n",
      "Epoch 5/12\n",
      "2137/2137 [==============================] - 18s 8ms/step - loss: 3.7328\n",
      "Epoch 6/12\n",
      "2137/2137 [==============================] - 17s 8ms/step - loss: 3.6660\n",
      "Epoch 7/12\n",
      "2137/2137 [==============================] - 17s 8ms/step - loss: 3.6080\n",
      "Epoch 8/12\n",
      "2137/2137 [==============================] - 18s 8ms/step - loss: 3.5562\n",
      "Epoch 9/12\n",
      "2137/2137 [==============================] - 19s 9ms/step - loss: 3.5091\n",
      "Epoch 10/12\n",
      "2137/2137 [==============================] - 19s 9ms/step - loss: 3.4652\n",
      "Epoch 11/12\n",
      "2137/2137 [==============================] - 19s 9ms/step - loss: 3.4243\n",
      "Epoch 12/12\n",
      "2137/2137 [==============================] - 19s 9ms/step - loss: 3.3857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f22c46164e0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(1, None)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (1, None, 300)            2160600   \n",
      "_________________________________________________________________\n",
      "unified_lstm_15 (UnifiedLSTM (1, None, 250)            551000    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (1, None, 7202)           1807702   \n",
      "=================================================================\n",
      "Total params: 4,519,302\n",
      "Trainable params: 4,519,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for prediction, batch size has to be changed\n",
    "# So reload the model and set shape to [1, None]\n",
    "\n",
    "# preloaded one checkpoint directory\n",
    "checkpoint_dir_preloaded = 'base_training_checkpoints_2020-02-28/'\n",
    "\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir_preloaded)\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_gen(model, start_string=START_STRING, freedom=1.0, num_generate=1000):\n",
    "    \"\"\"\n",
    "    generate text with the trained model\n",
    "    \n",
    "    start_string (STR):  Basis for the model to start prediction on. \n",
    "    freedom (FLOAT): Multiplier for predictions. The lower it is the lower the impact of predictive variance\n",
    "    num_generate (INT): Desired text length\n",
    "    \"\"\"\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "\n",
    "    # vectorization of starting string\n",
    "    input_eval = [word2idx[s] for s in tokenize(start_string)]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    model.reset_states()\n",
    "    \n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        \n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / freedom\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(' ') # spacing\n",
    "        text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN EPISODE wake - up of house . in a lifetime ] \n",
      " jeff : i didn't . it wouldn't help him . \n",
      " house :  [ ignoring him and amber ] i'm more 42 . can we checking through the best treatment ? \n",
      " house : and the church .  [ pulls a sign of his cane from the table ] \n",
      " house : pulmonary functions .  [ he walks over to face listening to the others as they both stare at house who continues .  ] \n",
      " cut to : \n",
      "  [ hospital room . day . dan’s parents are talking , version of chemo was helping that results . uh , you can’t still get your anywhere till tomorrow ; i can get some extra volume good stuff . \n",
      "  [ a card shines a tall guy enters the room ] \n",
      " thirteen : he offered him to keep on it . chase stands near the desk and a cup and pretends to jasper , a bit , guilty kneeling and a small cross . thirteen are attempting to spit her from a small hole from the table , wilson is watching them at each other ] \n",
      " foreman :  ( to audrey ) you choose the clock thinking ? \n",
      " jason : if she tried to kill him . \n",
      " house : med school , those are what she’s is killing the way up in the wrong play with you . \n",
      " della : who am i ? \n",
      " ted : that means we should let him die , seventh . \n",
      " cameron : how do you confirm not \n",
      " man : they can't ignore him ? \n",
      " house : is your only green doesn’t have affected her symptoms . \n",
      " wilson : she's sick . i thought more eight months ago . \n",
      " foreman :  ( editor ) but  [ pulls off the nasal to a - at the bottom of patrick's bed ] is an idiot .  ( about to him . she reacts in excitement . stacy has spiking on the ducklings with the atropine . cole starts ignoring him after naked . the camera pulls up in the room to him .  ] \n",
      "  [ hospital hallways . day .  ] \n",
      " nurse : only , it's more than no sign - how you could take a quarter ? \n",
      " andie : can we go in a coma \n",
      " wilson : it's a rash ? partner . \n",
      " chase : nothing's all right when i'm sure he said you are fascinating to buy her bones , or\n",
      " kutner stands in the rack closed deeply which is perhaps playing files with a bus in his crossed . \n",
      " brock : i'm going on to watch the catheter ? \n",
      " house :  ( heading through the from seven who had a gold star .  [ he starts pouring a tour - metal line , pulling the flowers and opens up and turns and walks away .  ] \n",
      " house : can be transmitted ! because you're an evolutionary cancer from you , and there are the best one drawing blood . cause i'm on the placebo . almost given up a vent which explains you just lose your , even lola : he reaches ct and reads to watch the rest of the .  ] \n",
      "  [ house flies back to his seat , annoyed , mostly chase : doctor man ? \n",
      " wilson : diagnostics office . chase and kutner are sitting by the conference table ) like , he's not fine for a kid . \n",
      "  [ cut to diagnostics office . house approaches him .  ] \n",
      "  [ he checks the where he’s on a present .  ] \n",
      " cut to : \n",
      "  [ diagnostics office . room , while quietly .  ] \n",
      " house : huh . the things i say , funny , i'm sorry . just want you for three documented a simple age , everything long as not screaming , him .  ) \n",
      " sarah : don't get to the world 'cause it doesn't fit the density . it'd suck the caps . among the brain . it's even one night . \n",
      " house : how could you try to stop ?  [ chase and kutner look at it , and grabbing his forehead ] \n",
      " hank : yeah , it must be a nice facility without telling house he's on the . foreman and thirteen are watching from a train , with a lot of symptoms . a lung check accounts . \n",
      " chase : most likely injury filling away in the er , it's some kind . \n",
      " chase : that’s it in on account of your symptoms . it’s okay , there’s only - threatening to me if they're not sleeping beauty . you're fine . \n",
      " house : now you saw anything else 'cause it's got some breakfast . \n",
      " cameron : what are you from the car ?  [ glancing at her ] mr . is 11 . and boring from six hours , or five and can be able to bring them at home . \n",
      " jeff : here we go quicker but went to the truth ! that's what i'm not running a green , and a lot of liking her eyes , and reads it is full of bacon . urine game slowly goes , to kiss the .  ] assuming this is a lot of paint you could never do . \n",
      " wilson : why’d you need leg : nah , you get the way off when did this kid's in an hour ? you are pregnant for hours . but did wilson : that's what to do . \n",
      " house : yeah , i should ever love you ? before i\n"
     ]
    }
   ],
   "source": [
    "print(text_gen(model, start_string=u\"BEGIN EPISODE\", freedom=1, num_generate=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BEGIN EPISODE [The scene opens on a dining the MRI scans and a blonde cough. Thirteen is standing behind her.]\n",
    " CUT TO:\n",
    " [Diagnostics Office. Day. The team is standing by the table in the courtroom. He sits back at the bedroom doorway]\n",
    " Vicodin administerately seriously. As soon as she holds on him, until he comes out of the Room and starts drilling it to him]\n",
    " Cuddy: You want him to take the webst now that I found the adjoining to someone's every \n",
    " Cuddy: You rather you're gonna have to give you a prescription about you, and I said you weren't right, if you transfer your case back from me, I'd be dead in a hospital. You can still get you scared, you're considering this out. People set up all the way back to the fact that it was inactive esperital in a canial dating again.\n",
    " House: Anything else?\n",
    " Foreman: Yeah, that would be idiots the way you two said it was never been in here and the recording studio that people in his shirt and white evolutionary symptoms. The clot could be a manifest rash \n",
    " Bill: We have to use it with him, we're sure it was his brain. [to Thirteen) You guys won't fire Chase.\n",
    " Cuddy: So what do we do? Tell you to take your pages for that disease?\n",
    " Melanie: Excuse me, [laughs] I know. I didn't know that you were worried about you.\n",
    " [House starts to walk away.]\n",
    " (Cut to Cameron and Chase in the conference room]\n",
    " Thirteen: You were wrong. The one that caused his car important aneurysm in the waiting room and House use it and down and sees House like him died]\n",
    " Foley: (getting the sharp panicking) Irene walking towards the classroom.]\n",
    " [Cut to a street coffired and releases the sample in the lobby.\n",
    " Cameron: The body doesn't work, they weren't all sure that work for. That doesn't mean she didn't comple here who was here. But I hear you were still alive. [All the walls look confused] You can't make sense go from those two people. You miss me right now if you're wrong with me, I say what I should try to teach you if you weren't going to do, I wanted to watch you changed your motorcycle, Dr. Foreman could’ve confronted it.\n",
    " Foreman: Yeah, but we didn't come back to your room for the bathroom because you think she was never the only mean something else which you caused. That wasn't that alone. [House takes it]\n",
    " Cuddy: The guy who was pretty much would be bacterial infection and a trache.\n",
    " [Cut to House and the team littering what is there as House and grin wheels Cuddy on the couch with his cane on a table in front of him. He slowly turns toward the refrigerator]\n",
    " [Cut to House walking into Bertingly athe in discretionances. Cuddy smiles and looks down, and throws up glass flashlight at Kenny’s face, then pauses and looks at the parents, he finishes writing the bottle of water on himself and collapses onto the floor, presents to people toward the office where Cuddy stands outside the door in front of the MRI, MRI made me someone paperwork and everyone stands beside him, everyone follows.]\n",
    " [Cut to Ducklings in the conference room. Cuddy is sitting at his desk in a chair while it looks around at the back of the bed)\n",
    " Michelle: If you're gonna have to go home soon enough.\n",
    " [Cut to House and Ducklings trying to stay him back and getting ready to dig down.]\n",
    " [Cut to the hallway. The team starts to walk away]\n",
    " Cuddy: What the hell is something to you?\n",
    " Cuddy: You don't have a chance.\n",
    " House: You don't want me to take the case you can\n",
    " [He tries to pull the eegisting up around to find a radiology video.\n",
    " Chase: We can do that on it. And get a blood tests were normal.\n",
    " Young Donny: Chase and Mark are you actually warn mother's clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
