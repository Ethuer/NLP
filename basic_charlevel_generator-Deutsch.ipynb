{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense ,Dropout,LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "badlist = pd.read_csv('data/badlist_de', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    \n",
    "    for badchar in badlist:\n",
    "        if badchar in line:\n",
    "            line = re.sub(badchar,'',line)\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw text files and clean the lines\n",
    "\n",
    "all_episodes_by_sentence = []\n",
    "\n",
    "seperators =  [' \\t\\n', '\\t\\n']\n",
    "\n",
    "with open('Newssnippets.txt',encoding='utf-8' ) as in_raw:\n",
    "    # start token\n",
    "    for (i, line) in enumerate(in_raw):\n",
    "        if not line in seperators:\n",
    "            all_episodes_by_sentence.append(clean_line(line) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donnerstag 08.08.2019 17:07 - Übermedien\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_episodes_by_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine text to create a single string for sliceshifting\n",
    "text = ' '.join(all_episodes_by_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 70, 69, ..., 60, 73,  0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 150\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 70, 69, ..., 60, 73,  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sequences from character dataset\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_shift_input(segment):\n",
    "    \"\"\"\n",
    "    Creates the teaching data by shifting the training data on off to create labeled data\n",
    "    \"\"\"\n",
    "    input_segment = segment[:-1]\n",
    "    target_segment = segment[1:]\n",
    "    return input_segment, target_segment\n",
    "\n",
    "dataset = sequences.map(split_shift_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset as prebatched\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "# Length of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# embedding dimension\n",
    "embedding_dim = 150\n",
    "\n",
    "# RNN units\n",
    "rnn_units = 256\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((35, 150), (35, 150)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    i = Input(shape=(None,), batch_size=batch_size )\n",
    "    x = Embedding(vocab_size, embedding_dim)(i)\n",
    "    x = LSTM(rnn_units, \n",
    "             return_sequences=True,\n",
    "             stateful=True,\n",
    "             recurrent_initializer='glorot_uniform')(x)\n",
    "    x = Dense(vocab_size)(x)\n",
    "    x = Dense(vocab_size)(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f60ccb47eb8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(35, None)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (35, None, 150)           15750     \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (35, None, 256)           416768    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (35, None, 105)           26985     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (35, None, 105)           11130     \n",
      "=================================================================\n",
      "Total params: 470,633\n",
      "Trainable params: 470,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    \"\"\"\n",
    "    Define loss function \n",
    "    \"\"\"\n",
    "    return sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss =loss)# loss='sparse_categorical_crossentropy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "today = date.today()\n",
    "\n",
    "checkpoint_dir = './base_training_checkpoints_{today}'.format(today=today)\n",
    "\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "# define callbacks\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Epoch 1/50\n",
      "265/265 [==============================] - 5s 18ms/step - loss: 2.7759\n",
      "Epoch 2/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 2.1733\n",
      "Epoch 3/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.9777\n",
      "Epoch 4/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.8540\n",
      "Epoch 5/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.7603\n",
      "Epoch 6/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.6852\n",
      "Epoch 7/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.6239\n",
      "Epoch 8/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.5730\n",
      "Epoch 9/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.5304\n",
      "Epoch 10/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.4941\n",
      "Epoch 11/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.4631\n",
      "Epoch 12/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.4361\n",
      "Epoch 13/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.4124\n",
      "Epoch 14/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3912\n",
      "Epoch 15/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3722\n",
      "Epoch 16/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3549\n",
      "Epoch 17/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3392\n",
      "Epoch 18/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3246\n",
      "Epoch 19/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3112\n",
      "Epoch 20/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2987\n",
      "Epoch 21/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2870\n",
      "Epoch 22/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2761\n",
      "Epoch 23/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2657\n",
      "Epoch 24/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2560\n",
      "Epoch 25/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2467\n",
      "Epoch 26/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2379\n",
      "Epoch 27/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2295\n",
      "Epoch 28/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2215\n",
      "Epoch 29/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2138\n",
      "Epoch 30/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.2065\n",
      "Epoch 31/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1994\n",
      "Epoch 32/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1927\n",
      "Epoch 33/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1862\n",
      "Epoch 34/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1799\n",
      "Epoch 35/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1739\n",
      "Epoch 36/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1680\n",
      "Epoch 37/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1624\n",
      "Epoch 38/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1569\n",
      "Epoch 39/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1517\n",
      "Epoch 40/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1467\n",
      "Epoch 41/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1417\n",
      "Epoch 42/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1368\n",
      "Epoch 43/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1323\n",
      "Epoch 44/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1277\n",
      "Epoch 45/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1234\n",
      "Epoch 46/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1191\n",
      "Epoch 47/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1150\n",
      "Epoch 48/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1111\n",
      "Epoch 49/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1073\n",
      "Epoch 50/50\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.1035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f60b05dd9b0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(1, None)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (1, None, 150)            15750     \n",
      "_________________________________________________________________\n",
      "unified_lstm_1 (UnifiedLSTM) (1, None, 256)            416768    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 105)            26985     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 105)            11130     \n",
      "=================================================================\n",
      "Total params: 470,633\n",
      "Trainable params: 470,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for prediction, batch size has to be changed\n",
    "# So reload the model and set shape to [1, None]\n",
    "\n",
    "# preloaded one checkpoint directory\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_gen(model, start_string, freedom=1.0, num_generate=1000):\n",
    "    \"\"\"\n",
    "    generate text with the trained model\n",
    "    \n",
    "    start_string (STR):  Basis for the model to start prediction on. \n",
    "    freedom (FLOAT): Multiplier for predictions. The lower it is the lower the impact of predictive variance\n",
    "    num_generate (INT): Desired text length\n",
    "    \"\"\"\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "\n",
    "    # vectorization of starting string\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    model.reset_states()\n",
    "    \n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        \n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / freedom\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montagg-·n-SQüstenruppen und dem Swassen und in der Sänger eine Ex-Freundin Laura Müller (19) scheinen Sänger Werber Lars Steiling musste er in der Band am Millionen Rammstein und der Sänger erscheinen Sieg geht die Sänger einen der Unterhaltung von George Rosenhe als Sänger Ben Affleck (42) haben die Trikot-Star und Deutschen Trico von Sänger Things die Ehe randem dazu: Er lustig an den Sänger und dessen Sohn Tom Kaulitz (30) zur Verfüg in der Samuel die Sänger für den Sänger und weitere Produktionsf\n"
     ]
    }
   ],
   "source": [
    "print(text_gen(model, start_string=u\"Montag\", freedom=0.5, num_generate=500))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BEGIN EPISODE [The scene opens on a dining the MRI scans and a blonde cough. Thirteen is standing behind her.]\n",
    " CUT TO:\n",
    " [Diagnostics Office. Day. The team is standing by the table in the courtroom. He sits back at the bedroom doorway]\n",
    " Vicodin administerately seriously. As soon as she holds on him, until he comes out of the Room and starts drilling it to him]\n",
    " Cuddy: You want him to take the webst now that I found the adjoining to someone's every \n",
    " Cuddy: You rather you're gonna have to give you a prescription about you, and I said you weren't right, if you transfer your case back from me, I'd be dead in a hospital. You can still get you scared, you're considering this out. People set up all the way back to the fact that it was inactive esperital in a canial dating again.\n",
    " House: Anything else?\n",
    " Foreman: Yeah, that would be idiots the way you two said it was never been in here and the recording studio that people in his shirt and white evolutionary symptoms. The clot could be a manifest rash \n",
    " Bill: We have to use it with him, we're sure it was his brain. [to Thirteen) You guys won't fire Chase.\n",
    " Cuddy: So what do we do? Tell you to take your pages for that disease?\n",
    " Melanie: Excuse me, [laughs] I know. I didn't know that you were worried about you.\n",
    " [House starts to walk away.]\n",
    " (Cut to Cameron and Chase in the conference room]\n",
    " Thirteen: You were wrong. The one that caused his car important aneurysm in the waiting room and House use it and down and sees House like him died]\n",
    " Foley: (getting the sharp panicking) Irene walking towards the classroom.]\n",
    " [Cut to a street coffired and releases the sample in the lobby.\n",
    " Cameron: The body doesn't work, they weren't all sure that work for. That doesn't mean she didn't comple here who was here. But I hear you were still alive. [All the walls look confused] You can't make sense go from those two people. You miss me right now if you're wrong with me, I say what I should try to teach you if you weren't going to do, I wanted to watch you changed your motorcycle, Dr. Foreman could’ve confronted it.\n",
    " Foreman: Yeah, but we didn't come back to your room for the bathroom because you think she was never the only mean something else which you caused. That wasn't that alone. [House takes it]\n",
    " Cuddy: The guy who was pretty much would be bacterial infection and a trache.\n",
    " [Cut to House and the team littering what is there as House and grin wheels Cuddy on the couch with his cane on a table in front of him. He slowly turns toward the refrigerator]\n",
    " [Cut to House walking into Bertingly athe in discretionances. Cuddy smiles and looks down, and throws up glass flashlight at Kenny’s face, then pauses and looks at the parents, he finishes writing the bottle of water on himself and collapses onto the floor, presents to people toward the office where Cuddy stands outside the door in front of the MRI, MRI made me someone paperwork and everyone stands beside him, everyone follows.]\n",
    " [Cut to Ducklings in the conference room. Cuddy is sitting at his desk in a chair while it looks around at the back of the bed)\n",
    " Michelle: If you're gonna have to go home soon enough.\n",
    " [Cut to House and Ducklings trying to stay him back and getting ready to dig down.]\n",
    " [Cut to the hallway. The team starts to walk away]\n",
    " Cuddy: What the hell is something to you?\n",
    " Cuddy: You don't have a chance.\n",
    " House: You don't want me to take the case you can\n",
    " [He tries to pull the eegisting up around to find a radiology video.\n",
    " Chase: We can do that on it. And get a blood tests were normal.\n",
    " Young Donny: Chase and Mark are you actually warn mother's clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
