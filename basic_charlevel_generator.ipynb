{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "from datetime import date\n",
    "\n",
    "from tensorflow.keras.layers import Input,Lambda, Dense,LeakyReLU ,Dropout,LSTM, GlobalMaxPool1D, Bidirectional, Embedding,Flatten, Concatenate,Conv2DTranspose , BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "badlist = pd.read_csv('data/badlist', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    \n",
    "    for badchar in badlist:\n",
    "        if badchar in line:\n",
    "            line = re.sub(badchar,'',line)\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw text files and clean the lines\n",
    "\n",
    "START_STRING = 'BEGIN EPISODE'\n",
    "\n",
    "all_episodes_by_sentence = []\n",
    "\n",
    "for element in os.listdir('house/'):\n",
    "    if 'clean' in element:\n",
    "        with open('house/'+element) as in_raw:\n",
    "            # start token\n",
    "            all_episodes_by_sentence.append(START_STRING)\n",
    "            for (i, line) in enumerate(in_raw):\n",
    "                all_episodes_by_sentence.append(clean_line(line) )\n",
    "        \n",
    "            # end token\n",
    "            all_episodes_by_sentence.append('END EPISODE\\n\\n')\n",
    "            all_episodes_by_sentence.append('------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEGIN EPISODE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_episodes_by_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine text to create a single string for sliceshifting\n",
    "text = ' '.join(all_episodes_by_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 36, 38, ..., 13, 13,  1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 200\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 36, 38, ..., 13, 13,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'BEGIN EPISODE [Open on a House’s face. His eyes are closed. The picture is not quite in color, but it’s not black and white either. Radiohead’s “No Surprises” plays.]\\n [House opens his eyes. He’s lying'\n",
      "' on a twin bed on the left side of a cell-like room at Mayfield. He’s wearing a gray t-shirt. There is a stainless steel basin on the tiled floor near his head. On the opposite wall there is a single w'\n",
      "'indow. Next to it a metal sink is bolted into the wall. Another stainless basin is on the floor below the sink.]\\n [Cut to House opening his eyes. The color has returned to normal. Everything is quiet. '\n",
      "'He isn’t restrained any longer. He touches his thigh briefly then sits up. He limps to the window, holding his leg for support.]\\n [Cut to a suitcase dropping on the bed. House packs his clothes and zip'\n",
      "'s the valise.]\\n [Cut to House walking down the hall with his cane in his right hand and his suitcase in his left. He switches the case to his right so he can swipe a knit cap off a patient in a wheelch'\n"
     ]
    }
   ],
   "source": [
    "# extract sequences from character dataset\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_shift_input(segment):\n",
    "    \"\"\"\n",
    "    Creates the teaching data by shifting the training data on off to create labeled data\n",
    "    \"\"\"\n",
    "    input_segment = segment[:-1]\n",
    "    target_segment = segment[1:]\n",
    "    return input_segment, target_segment\n",
    "\n",
    "dataset = sequences.map(split_shift_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'BEGIN EPISODE [Open on a House’s face. His eyes are closed. The picture is not quite in color, but it’s not black and white either. Radiohead’s “No Surprises” plays.]\\n [House opens his eyes. He’s lyin'\n",
      "Target data: 'EGIN EPISODE [Open on a House’s face. His eyes are closed. The picture is not quite in color, but it’s not black and white either. Radiohead’s “No Surprises” plays.]\\n [House opens his eyes. He’s lying'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset as prebatched\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "# Length of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN units\n",
    "rnn_units = 1124\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((35, 200), (35, 200)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    i = Input(shape=(None,), batch_size=batch_size )\n",
    "    x = Embedding(vocab_size, embedding_dim)(i)\n",
    "    x = LSTM(rnn_units, \n",
    "             return_sequences=True,\n",
    "             stateful=True,\n",
    "             recurrent_initializer='glorot_uniform')(x)\n",
    "    x = Dense(vocab_size)(x)\n",
    "    x = Dense(vocab_size)(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(35, None)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (35, None, 256)           24320     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (35, None, 1124)          6208976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (35, None, 95)            106875    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (35, None, 95)            9120      \n",
      "=================================================================\n",
      "Total params: 6,349,291\n",
      "Trainable params: 6,349,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    \"\"\"\n",
    "    Define loss function \n",
    "    \"\"\"\n",
    "    return sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss =loss)# loss='sparse_categorical_crossentropy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "today = date.today()\n",
    "\n",
    "checkpoint_dir = './base_training_checkpoints_{today}'.format(today=today)\n",
    "\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "# define callbacks\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    757/Unknown - 100s 132ms/step - loss: 2.0815"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction, batch size has to be changed\n",
    "# So reload the model and set shape to [1, None]\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_gen(model, start_string=START_STRING, freedom=1.0, num_generate=1000):\n",
    "    \"\"\"\n",
    "    generate text with the trained model\n",
    "    \n",
    "    start_string (STR):  Basis for the model to start prediction on. \n",
    "    freedom (FLOAT): Multiplier for predictions. The lower it is the lower the impact of predictive variance\n",
    "    num_generate (INT): Desired text length\n",
    "    \"\"\"\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    # Number of characters to generate\n",
    "    num_generate = 10000\n",
    "\n",
    "    # vectorization of starting string\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    model.reset_states()\n",
    "    \n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        \n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / freedom\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(text_gen(model, start_string=u\"BEGIN EPISODE\", freedom=0.7, num_generate=10000))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BEGIN EPISODE [The scene opens on a dining the MRI scans and a blonde cough. Thirteen is standing behind her.]\n",
    " CUT TO:\n",
    " [Diagnostics Office. Day. The team is standing by the table in the courtroom. He sits back at the bedroom doorway]\n",
    " Vicodin administerately seriously. As soon as she holds on him, until he comes out of the Room and starts drilling it to him]\n",
    " Cuddy: You want him to take the webst now that I found the adjoining to someone's every \n",
    " Cuddy: You rather you're gonna have to give you a prescription about you, and I said you weren't right, if you transfer your case back from me, I'd be dead in a hospital. You can still get you scared, you're considering this out. People set up all the way back to the fact that it was inactive esperital in a canial dating again.\n",
    " House: Anything else?\n",
    " Foreman: Yeah, that would be idiots the way you two said it was never been in here and the recording studio that people in his shirt and white evolutionary symptoms. The clot could be a manifest rash \n",
    " Bill: We have to use it with him, we're sure it was his brain. [to Thirteen) You guys won't fire Chase.\n",
    " Cuddy: So what do we do? Tell you to take your pages for that disease?\n",
    " Melanie: Excuse me, [laughs] I know. I didn't know that you were worried about you.\n",
    " [House starts to walk away.]\n",
    " (Cut to Cameron and Chase in the conference room]\n",
    " Thirteen: You were wrong. The one that caused his car important aneurysm in the waiting room and House use it and down and sees House like him died]\n",
    " Foley: (getting the sharp panicking) Irene walking towards the classroom.]\n",
    " [Cut to a street coffired and releases the sample in the lobby.\n",
    " Cameron: The body doesn't work, they weren't all sure that work for. That doesn't mean she didn't comple here who was here. But I hear you were still alive. [All the walls look confused] You can't make sense go from those two people. You miss me right now if you're wrong with me, I say what I should try to teach you if you weren't going to do, I wanted to watch you changed your motorcycle, Dr. Foreman could’ve confronted it.\n",
    " Foreman: Yeah, but we didn't come back to your room for the bathroom because you think she was never the only mean something else which you caused. That wasn't that alone. [House takes it]\n",
    " Cuddy: The guy who was pretty much would be bacterial infection and a trache.\n",
    " [Cut to House and the team littering what is there as House and grin wheels Cuddy on the couch with his cane on a table in front of him. He slowly turns toward the refrigerator]\n",
    " [Cut to House walking into Bertingly athe in discretionances. Cuddy smiles and looks down, and throws up glass flashlight at Kenny’s face, then pauses and looks at the parents, he finishes writing the bottle of water on himself and collapses onto the floor, presents to people toward the office where Cuddy stands outside the door in front of the MRI, MRI made me someone paperwork and everyone stands beside him, everyone follows.]\n",
    " [Cut to Ducklings in the conference room. Cuddy is sitting at his desk in a chair while it looks around at the back of the bed)\n",
    " Michelle: If you're gonna have to go home soon enough.\n",
    " [Cut to House and Ducklings trying to stay him back and getting ready to dig down.]\n",
    " [Cut to the hallway. The team starts to walk away]\n",
    " Cuddy: What the hell is something to you?\n",
    " Cuddy: You don't have a chance.\n",
    " House: You don't want me to take the case you can\n",
    " [He tries to pull the eegisting up around to find a radiology video.\n",
    " Chase: We can do that on it. And get a blood tests were normal.\n",
    " Young Donny: Chase and Mark are you actually warn mother's clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
